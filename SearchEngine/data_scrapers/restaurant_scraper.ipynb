{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TA scraper for Restaurant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79vjrENrMT1e",
    "outputId": "5c118b49-fa65-4eec-bac0-9a2ef861715a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Mu2KGE3LMTHP"
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import pandas as pd\n",
    "import requests\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import argparse\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WrJx7SdLMTHU"
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    if text:\n",
    "        # Removing \\n \\r and \\t\n",
    "        return ' '.join(''.join(text).split()).strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y67s_8NFMTHV"
   },
   "outputs": [],
   "source": [
    "def process_request(url, retry=0):\n",
    "    print('Fetching {}'.format(url))\n",
    "    headers = {\n",
    "                \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "                \"accept-encoding\": \"gzip, deflate, br\",\n",
    "                \"accept-language\": \"en-GB,en;q=0.9,en-US;q=0.8,ml;q=0.7\",\n",
    "                \"cache-control\": \"max-age=0\",\n",
    "                \"upgrade-insecure-requests\": \"1\",\n",
    "                \"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 Safari/537.36\",\n",
    "            }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        return {'error': 'Page not found', 'status_code': 404}\n",
    "\n",
    "    parser = html.fromstring(response.text, url)\n",
    "    return process_page(parser, url)\n",
    "\n",
    "\n",
    "def process_page(parser, url):\n",
    "    script_text = ' '.join(''.join(parser.xpath('//script//text()')).split())\n",
    "    try:\n",
    "        raw_name = re.findall(\"FoodEstablishment\\\"\\,\\\"name\\\"\\:\\\"[a-zA-Z0-9 \\.\\-\\']{2,}\\\"\", script_text)[0]\n",
    "        raw_name = raw_name[27:-1]\n",
    "    except:\n",
    "        raw_name = ''\n",
    "        \n",
    "    try:\n",
    "        raw_description = re.findall(\"\\\"description\\\"\\:\\\"[A-Za-z0-9 ,'.\\-]{10,}\", script_text)[0]\n",
    "        raw_description = raw_description[15:]\n",
    "    except:\n",
    "        raw_description = ''\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        raw_features = re.findall(\"\\]\\}\\,\\\"features\\\"\\:\\{\\\"[A-Za-z0-9 ,\\\"'.\\-\\:\\[\\{\\}]{10,}\\]\", script_text)\n",
    "        raw_features =raw_features[0][42:]\n",
    "        jsn_f = json.loads(raw_features)\n",
    "        features = ''\n",
    "        for f in jsn_f:\n",
    "            features+=f['tagValue']\n",
    "            features+=', '\n",
    "    except:\n",
    "        features = ''\n",
    "    try:    \n",
    "        raw_cuisines = re.findall(\"\\]\\}\\,\\\"cuisines\\\"\\:\\{\\\"[A-Za-z0-9 ,\\\"'.\\-:\\[\\{\\}]{10,}\\]\", script_text)\n",
    "        raw_cuisines =raw_cuisines[0][42:]\n",
    "        jsn_f = json.loads(raw_cuisines)\n",
    "        cuisines = ''\n",
    "        for f in jsn_f:\n",
    "            cuisines+=f['tagValue']\n",
    "            cuisines+=', '\n",
    "    except:\n",
    "        cuisines = ''\n",
    "    try:\n",
    "      raw_meals = re.findall(\"\\]\\}\\,\\\"meals\\\"\\:\\{\\\"[A-Za-z0-9 ,\\\"'.\\-:\\[\\{\\}]{10,}\\]\", script_text)\n",
    "      raw_meals =raw_meals[0][39:]\n",
    "      jsn_f = json.loads(raw_meals)\n",
    "      meals = ''\n",
    "      for f in jsn_f:\n",
    "          meals+= f['tagValue']\n",
    "          meals+=', '\n",
    "    except:\n",
    "      meals = ''\n",
    "    try:  \n",
    "      raw_dietary = re.findall(\"\\]\\}\\,\\\"dietaryRestrictions\\\"\\:\\{\\\"[A-Za-z0-9 ,\\\"'.\\-:\\[\\{\\}]{10,}\\]\", script_text)\n",
    "      raw_dietary =raw_dietary[0][53:]\n",
    "      jsn_f = json.loads(raw_dietary)\n",
    "      dietary = ''\n",
    "      for f in jsn_f:\n",
    "          dietary+= f['tagValue']\n",
    "          dietary+=', '\n",
    "    except:  \n",
    "        dietary = ''\n",
    "    try:   \n",
    "      raw_image = re.findall(\"\\\"images\\\"\\:\\{[A-Za-z0-9 \\,\\'\\\".\\-\\:\\{\\}/]{10,}\\}\\}\", script_text)[0]      \n",
    "      raw_image = raw_image[9:-1]\n",
    "      image = json.loads(raw_image)['original']['url']\n",
    "    except:\n",
    "        image = ''\n",
    "    try:    \n",
    "      lat = re.findall(\"latitude\\\"\\:[0-9 -]{1,}\\.[0-9]{1,}\", script_text)[0]\n",
    "      lon = re.findall(\"longitude\\\"\\:[0-9 -]{1,}\\.[0-9]{1,}\", script_text)[0]\n",
    "    except:\n",
    "      lat = ''\n",
    "      lon = ''\n",
    "    XPATH_FULL_ADDRESS_JSON = '//script[@type=\"application/ld+json\"]//text()'\n",
    "    \n",
    "    raw_address_json = parser.xpath(XPATH_FULL_ADDRESS_JSON)\n",
    "    \n",
    "    hotel_rating = 0\n",
    "    address = {}\n",
    "    if raw_address_json:\n",
    "        try:\n",
    "            parsed_address_info = json.loads(raw_address_json[0])\n",
    "            rating = parsed_address_info.get('aggregateRating', {})\n",
    "            address = parsed_address_info.get(\"address\", {})\n",
    "                \n",
    "            hotel_rating = rating.get('ratingValue')\n",
    "            review_count = rating.get('reviewCount')\n",
    "            \n",
    "        except Exception as e:\n",
    "            review_count = hotel_rating = 0\n",
    "            raise e\n",
    "\n",
    "    additional_info_dict = OrderedDict()\n",
    "    \n",
    "    data = {\n",
    "            'name': raw_name,\n",
    "            'features': features,\n",
    "            'cuisines' : cuisines,\n",
    "            'meals' : meals,\n",
    "            'special meals' :dietary,\n",
    "            'official_description': raw_description,\n",
    "            'rating': float(hotel_rating) if hotel_rating else 0.0,\n",
    "            'street': address.get('streetAddress'),\n",
    "            'country': address.get(\"addressCountry\", {}).get(\"name\"),\n",
    "            'region': address.get('addressRegion'),\n",
    "            'coords':{\n",
    "                'latitude' : lat[10:],\n",
    "                'longitude' : lon[11:]\n",
    "                },\n",
    "            'image' : image,\n",
    "            \n",
    "    }\n",
    "    try:\n",
    "        data.update({'price' : min(price)})\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j78tEgk7MTHW"
   },
   "outputs": [],
   "source": [
    "def info_request(url): \n",
    "    # try:\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('url', help='Tripadvisor hotel url')\n",
    "  scraped_data = process_request(url)\n",
    "  return  scraped_data\n",
    "    # except:\n",
    "    #     pass\n",
    "    \n",
    "\n",
    "def save_json(scraped_data):\n",
    "    with open('/content/drive/MyDrive/final_dataset.json', 'w') as f:\n",
    "        json.dump(scraped_data, f, indent=4, ensure_ascii=False)\n",
    "    return 'Done!'\n",
    "\n",
    "def get_dataset(df, glb_cnt = 0):\n",
    "    fnl_res = {}\n",
    "    cnt = glb_cnt\n",
    "    for row in df.url:\n",
    "        url = row \n",
    "        res = info_request(url)\n",
    "        fnl_res.update({cnt : res})\n",
    "        cnt+= 1\n",
    "        print(cnt)\n",
    "        if cnt == df.size + glb_cnt:\n",
    "            break\n",
    "    return cnt, fnl_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5paYge1VMTHW"
   },
   "outputs": [],
   "source": [
    "files = os.listdir('/content/drive/MyDrive/parts2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xviIVXsgLkD",
    "outputId": "33083a40-c0c1-433f-8f03-e8a7ef598733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Restaurants_Ankara_2021-04-01.csv',\n",
       " 'Restaurants_Antalya_2021-04-01.csv',\n",
       " 'Restaurants_Bodrum_2021-04-01.csv',\n",
       " 'Restaurants_California_2021-04-01.csv',\n",
       " 'Restaurants_China_2021-04-01.csv',\n",
       " 'Restaurants_Iran_2021-04-01.csv',\n",
       " 'Restaurants_Istanbul_2021-04-01.csv',\n",
       " 'Restaurants_New Yourk_2021-04-01.csv',\n",
       " 'Restaurants_Texas_2021-04-01.csv',\n",
       " 'Restaurants_Tokyo_2021-04-01.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zVcifmi2MTHW",
    "outputId": "955b9e66-75fa-4574-8b33-981f5fb3b042"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Restaurants_New Yourk_2021-04-01.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = files[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B59gthB9JF2Z"
   },
   "outputs": [],
   "source": [
    "df =  pd.read_csv(\"/content/drive/MyDrive/parts2/{}\".format(file))\n",
    "for file in files:\n",
    "  df = df.append(pd.read_csv(\"/content/drive/MyDrive/parts2/{}\".format(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UYoEj9g_JPAO"
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FVaZQGeHwphT"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/content/drive/MyDrive/parts/{}\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ubWELs01ihuc",
    "outputId": "18305d2e-bc9c-469d-9426-de187f318944"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.tripadvisor.com/Restaurant_Review-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url\n",
       "0  https://www.tripadvisor.com/Restaurant_Review-...\n",
       "1  https://www.tripadvisor.com/Restaurant_Review-...\n",
       "2  https://www.tripadvisor.com/Restaurant_Review-...\n",
       "3  https://www.tripadvisor.com/Restaurant_Review-...\n",
       "4  https://www.tripadvisor.com/Restaurant_Review-..."
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "deYF9AzhxjOS"
   },
   "outputs": [],
   "source": [
    "# df = df.iloc[50:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MgM4P00mtQfX"
   },
   "outputs": [],
   "source": [
    "#  df['hotel_url'][2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbaFApK-8yR3",
    "outputId": "f933acc0-f7bf-4286-b8ca-06a01376b0e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFWC3l5cuKI3",
    "outputId": "3ffddc9d-9a8f-47b6-e12f-6d512adb6bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d14109193-Reviews-Yakiniku_Kyoshotei_Ginza-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "301\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14133707-d8283419-Reviews-Nabezo_Shinjuku_Meijidori-Shinjuku_3_Chome_Shinjuku_Tokyo_Tokyo_Prefecture_Kant.html\n",
      "302\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066456-d12708952-Reviews-Gyukatsu_Motomura_Harajuku-Shibuya_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "303\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14134311-d1904872-Reviews-Kikko-Asakusa_Taito_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "304\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14133707-d1676825-Reviews-Nabezo_Shinjuku_3_Chome-Shinjuku_3_Chome_Shinjuku_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "305\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d6070758-Reviews-Steak_House_Hama_Ginza-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "306\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066443-d8179337-Reviews-Honey_Toast_Cafe_Akihabara-Chiyoda_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "307\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066456-d7812649-Reviews-Maidreamin_SHIBUYA-Shibuya_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "308\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066457-d9669468-Reviews-Trattoria_Dai_Paesani-Shinjuku_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "309\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14133667-d8356861-Reviews-Teppan_Baby_Shinjuku-Kabukicho_Shinjuku_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "310\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066456-d8449399-Reviews-Glutenfree_Cafe_Littlebird-Shibuya_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "311\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066854-d1692134-Reviews-Sushiryori_Inose-Shinagawa_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "312\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d3808458-Reviews-Ginza_300BAR_8_Chome-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "313\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d13168364-Reviews-Yakiniku_a_Five_Toku_Ginza8chome-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "314\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129743-d1698731-Reviews-Izakaya_Sanzoku-Akasaka_Minato_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "315\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066443-d12163097-Reviews-Kawai_Maid_Cafe_Bar_Akiba_Zettai_Ryoiki-Chiyoda_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "316\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129743-d2248008-Reviews-Towers-Akasaka_Minato_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "317\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d1672067-Reviews-Tempura_Abe_Ginza_Honten-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "318\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066443-d9669239-Reviews-Akiba_Seasonal_Seafood_Izakaya_Uo_No_Ma-Chiyoda_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "319\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d1677573-Reviews-Ippou-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "320\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066442-d14948292-Reviews-Yataiya_Hakatagekijo_Ueno_Hirokoji-Bunkyo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "321\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d9964457-Reviews-Bar_Yu_Nagi-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "322\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129536-d3808465-Reviews-New_Tokyo_Beer_Hall_Sukiyabashi_Honten-Yurakucho_Chiyoda_Tokyo_Tokyo_Prefecture.html\n",
      "323\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d10087853-Reviews-Ginza_300BAR_5_Chome-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "324\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129528-d12958888-Reviews-Kurokatsutei_Tokyo_Station-Marunouchi_Chiyoda_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "325\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d8091134-Reviews-Kyoto_Hyoki_Ginza_Sanchome_branch-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "326\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d13823114-Reviews-175_Deno_Tantan_Men_Ginza-Ginza_Chuo_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "327\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g14129573-d14068181-Reviews-Shabu_Shabu_Yakiniku_Tabehoudai_Merino_Ginza-Ginza_Chuo_Tokyo_Tokyo_Prefecture.html\n",
      "328\n",
      "Fetching https://www.tripadvisor.com/Restaurant_Review-g1066443-d4668075-Reviews-Wogo_Gyoza-Chiyoda_Tokyo_Tokyo_Prefecture_Kanto.html\n",
      "329\n",
      "data\n",
      "329\n",
      "data\n",
      "329\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "  for i in range(0,3):\n",
    "    try:\n",
    "      with open('/content/drive/MyDrive/final_dataset.json', 'r+') as f:\n",
    "        try:\n",
    "          da = json.load(f)\n",
    "        except:\n",
    "          da = {}\n",
    "      idx = len(da)\n",
    "      print(idx)\n",
    "      fnl_res= {}\n",
    "      cnt,res = get_dataset(df.head(100), idx)\n",
    "      print('data')\n",
    "      fnl_res.update(res)\n",
    "      with open('/content/drive/MyDrive/final_dataset.json', 'r+') as f:\n",
    "        try:\n",
    "          data = json.load(f)\n",
    "        except:\n",
    "          data = {}\n",
    "      data.update(fnl_res)    \n",
    "      save_json(data)\n",
    "      df = df.iloc[100:]      \n",
    "    except:\n",
    "      pass\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-VEDa38mMTHZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hotels_scraper (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
